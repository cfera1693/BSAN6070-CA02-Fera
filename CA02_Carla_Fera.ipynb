{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02 - Carla Fera.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4CZuxE85fZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import all necessary packages in other to run the Naibe Bayes Algorithm. \n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYLMmZ-75tjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The main objective of this function is to make a dictionary that contains the most frequent/common words in the emails. \n",
        "#This is because according to the most common used words on each type of email (not spam/spam),\n",
        "#Naive Bayes Algorithm will classify each one of them to their corresponding category.   \n",
        "\n",
        "def make_Dictionary(root_dir): #def is the function to define another function, in this case the function called \"make_Dictionary\".\n",
        "  all_words = [] # this line of code creates an empty list called \"all words\".\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #this line of code passes a directory into a variable, in this case, the directory of the emails. \n",
        "  for mail in emails: # here we start a for loop to open each email, and go throw each line of the email, and split each line into words. Then save the words into the list \"all_words\".\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words # this line of code sabes each word into a list, all_words. \n",
        "  dictionary = Counter(all_words) # Counter is a class which is used with hashable objects. It creates a dictionarty with the count of each corresponding word.  \n",
        "  list_to_remove = list(dictionary) # converts the dictionary created above into a list. \n",
        "\n",
        "#In this part of the code, we are trying to remove the numeric values, which are not relevant to our study, and also any alpha-numeric value that is 1 character long. \n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False: # If alpha is False, meaning if its not a word compounded with letters , it will delete this number. \n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1: #In this statement, if is not a number, but it is of length 1, it will delete it as well. \n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000) # Finally, once we have all the words \"cleaned\", without numbers or undesirable characters, with select the 3000 most commont/used words and store them. \n",
        "  return dictionary\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnu1gArI14ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The objective of this function is to generate a label and word frequency matrix. The labels are the unique words in the emails. \n",
        "\n",
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] # This line of code extracts the emails from the directory and save them in files variable. \n",
        "  features_matrix = np.zeros((len(files),3000)) # Here, a matrix is created filled with zeros. \n",
        "  train_labels = np.zeros(len(files)) # a numpy array is created filled with zeros. \n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files: # This is a for loop to iterate through the files/emails. \n",
        "    with open(fil) as fi: # this line of code open each file/email. \n",
        "      for i, line in enumerate(fi): # Enumarate method adds a counter to an iterable and returns it in a form of enumerate object. In this case, it enumarates the number emails to pass thorugh the for loop. \n",
        "        if i ==2: #if the number of words is equal to two then:\n",
        "          words = line.split() # split the words and save them into a variable \"word\". \n",
        "          for word in words: #Initiates a for loop, for each word in the list of \"words\". \n",
        "            wordID = 0 # This line of codes sets the variable wordID to zero. \n",
        "            for i, d in enumerate(dictionary): # This loop iterated through the words in the dictionary previously created in the other function. \n",
        "              if d[0] == word: # if the first element of the dictionary is equal to the first word in words list, then assing a wordID to that word which is i. \n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word) # create a matrix with docID, which is equal to 0, And wordID, which will keep changing according to the for loop and the values of i. In this step we fill out our matrix.\n",
        "      train_labels[docID] = 0; # set train_labels, index docID, to zero. \n",
        "      filepathTokens = fil.split('/') #slip each file/email when a \"/\" appears. \n",
        "      lastToken = filepathTokens[len(filepathTokens)-1] #Selects the last 'sentence' in filepathTokens. \n",
        "      if lastToken.startswith(\"spmsg\"): #a condition in which checks if the email is an spam. If it is then, the following codes will run. \n",
        "        train_labels[docID] = 1; \n",
        "        count = count + 1 # so it starts making a counter for every spam email. \n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNIwm8rTnAVX",
        "colab_type": "code",
        "outputId": "e8fd9d80-a0aa-49c9-81fe-7b4f86c31114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#Finally, in this part of the code where we start applying the Naive Bayes Algorithm, which is based in conditional probabilities. \n",
        "\n",
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/train-mails' # These are the paths where the emails are located. \n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/test-mails'\n",
        "\n",
        "dictionary = make_Dictionary(TRAIN_DIR) # Applies the function created in first place and makes a dictionary of the most common words. \n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR) # Applies the second function to extract the features or variables necessary to run the algorithm. \n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR) # use the same function for the emails in the test set. \n",
        "\n",
        "model = GaussianNB() # Selects the type of Naive Bayes to apply. \n",
        "\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels) # fits the model into the training set. \n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix) # Predicts or classify the emails on the test set. \n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels)) # Prints the accuracy of the model. \n",
        "\n",
        "\"\"\"======================= END OF PROGRAM =========================\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'======================= END OF PROGRAM ========================='"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}